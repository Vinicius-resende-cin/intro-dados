{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de partidas de xadrez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão criados modelos de classificação para prever o vencedor de partidas de xadrez, baseado em dados pré-processados no projeto anterior.\n",
    "\n",
    "Será utilizado o MLFlow para rastreamento de experimentos e comparação de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração do MLFLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "mlflow.set_experiment(experiment_name='Chess games classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do método de rastreamento do mlflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_track(model, model_name: str, params: dict, metrics: dict):\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(sk_model=model, artifact_path=\"sklearn-model\", registered_model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do método para plotar resultados do treinamento de um modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search(results: dict, param: str):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(\"GridSearchCV evaluating\", fontsize=16)\n",
    "\n",
    "    plt.xlabel(\"min_samples_split\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "    # Get the regular numpy array from the MaskedArray\n",
    "    X_axis = np.array(results[\"param_%s\" % param].data, dtype=float)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    for sample, style in ((\"train\", \"--\"), (\"test\", \"-\")):\n",
    "        sample_score_mean = results[\"mean_%s_score\" % sample]\n",
    "        sample_score_std = results[\"std_%s_score\" % sample]\n",
    "        ax.fill_between(\n",
    "            X_axis,\n",
    "            sample_score_mean - sample_score_std,\n",
    "            sample_score_mean + sample_score_std,\n",
    "            alpha=0.1 if sample == \"test\" else 0,\n",
    "            color='g',\n",
    "        )\n",
    "        ax.plot(\n",
    "            X_axis,\n",
    "            sample_score_mean,\n",
    "            style,\n",
    "            color='g',\n",
    "            alpha=1 if sample == \"test\" else 0.7,\n",
    "            label=\"%s (%s)\" % (\"Accuracy\", sample),\n",
    "        )\n",
    "\n",
    "    best_index = np.nonzero(results[\"rank_test_score\"] == 1)[0][0]\n",
    "    best_score = results[\"mean_test_score\"][best_index]\n",
    "\n",
    "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "    ax.plot(\n",
    "        [\n",
    "            X_axis[best_index],\n",
    "        ]\n",
    "        * 2,\n",
    "        [0, best_score],\n",
    "        linestyle=\"-.\",\n",
    "        color='g',\n",
    "        marker=\"x\",\n",
    "        markeredgewidth=3,\n",
    "        ms=8,\n",
    "    )\n",
    "\n",
    "    # Annotate the best score for that scorer\n",
    "    ax.annotate(\"%0.2f\" % best_score, (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do método de treinamento e rastreamento do mlflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_train_and_track(model_class, model_name, train_data: pd.DataFrame, target: str, param_grid: dict, params: dict = {}):\n",
    "    # Split the data labels and features\n",
    "    train_x = train_data.drop([target], axis=1)\n",
    "    train_y = train_data[[target]]\n",
    "\n",
    "    # Train the model and track\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Train the model with a grid search\n",
    "        model = model_class(**params)\n",
    "        gs = GridSearchCV(\n",
    "            model,\n",
    "            param_grid=param_grid,\n",
    "            n_jobs=2,\n",
    "            return_train_score=True\n",
    "        )\n",
    "        gs.fit(train_x, train_y)\n",
    "        results = gs.cv_results_\n",
    "        print(results[sorted(param_grid)[0]])\n",
    "        #scores = cross_val_score(model, train_x, train_y)\n",
    "\n",
    "        # Print the results\n",
    "        print(\"Trained %s(%s).\" %(model_name, str(params).strip(\"{}\")))\n",
    "        #print(\"Results: %0.4f mean accuracy with a std of %0.4f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "        # Plot the grid search results of the first parameter\n",
    "        plot_grid_search(results, list(param_grid.keys())[0])\n",
    "\n",
    "        # Log best model to MLflow\n",
    "        best_model = gs.best_estimator_\n",
    "        best_params = gs.best_params_\n",
    "        best_score = gs.best_score_\n",
    "        mlflow_track(best_model, model_name, best_params, {\"mean_accuracy\": best_score.mean(), \"std_accuracy\": best_score.std()})\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando os modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = \"https://raw.githubusercontent.com/Vinicius-resende-cin/intro-dados/master/data/chess_games_cleaned.csv\"\n",
    "try:\n",
    "    data = pd.read_csv(csv_url, encoding = \"ISO-8859-1\")\n",
    "except Exception as e:\n",
    "    logger.exception(f\"Unable to download training & test CSV, check your internet connection. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertendo tipos para execução dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['victory_status'] = data['victory_status'].astype('category')\n",
    "data['winner'] = data['winner'].astype('category')\n",
    "data['increment_code'] = data['increment_code'].astype('category')\n",
    "data['white_id'] = data['white_id'].astype('category')\n",
    "data['black_id'] = data['black_id'].astype('category')\n",
    "data['moves'] = data['moves'].astype('category')\n",
    "data['opening_eco'] = data['opening_eco'].astype('category')\n",
    "data['opening_name'] = data['opening_name'].astype('category')\n",
    "\n",
    "data['victory_status'] = data['victory_status'].cat.codes\n",
    "data['winner'] = data['winner'].cat.codes\n",
    "data['increment_code'] = data['increment_code'].cat.codes\n",
    "data['white_id'] = data['white_id'].cat.codes\n",
    "data['black_id'] = data['black_id'].cat.codes\n",
    "data['moves'] = data['moves'].cat.codes\n",
    "data['opening_eco'] = data['opening_eco'].cat.codes\n",
    "data['opening_name'] = data['opening_name'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando dados de treinamento e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets. (0.75, 0.22) split.\n",
    "train_data, test_data = train_test_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executando o treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar o rastreamento numa interface, execute o comando abaixo no diretório deste notebook (`/notebooks`):\n",
    "\n",
    "```bash\n",
    "mlflow ui --port 5000\n",
    "```\n",
    "\n",
    "A interface será acessível no endereço `http://localhost:5000` em um navegador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest_param_grid = {\n",
    "    \"n_estimators\": range(10, 500, 50),\n",
    "    \"max_depth\": range(1, 100, 20),\n",
    "    \"min_samples_leaf\": range(1, 30, 5)\n",
    "}\n",
    "mlflow_train_and_track(RandomForestClassifier, \"RandomForest\", train_data, \"winner\", random_forest_param_grid, {\"random_state\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_param_grid = {\n",
    "    \"n_neighbors\": range(3, 50, 2)\n",
    "}\n",
    "mlflow_train_and_track(KNeighborsClassifier, 'KNN', train_data, 'winner', knn_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc_param_grid = {\n",
    "    'C': range(0.1, 100.0, 1.0)\n",
    "}\n",
    "mlflow_train_and_track(LinearSVC, 'SVC', train_data, 'winner', svc_param_grid, {\"random_state\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_param_grid = {\n",
    "    'alpha': range(0.1, 10.0, 0.5),\n",
    "    'max_iter': range(100, 1000, 100)\n",
    "}\n",
    "mlflow_train_and_track(MLPClassifier, 'MLP', train_data, 'winner', mlp_param_grid, {\"random_state\": 0})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
